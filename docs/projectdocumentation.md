# ğŸ“– Multi-Agent Content Generation System â€” Full Documentation

> *A deep dive into how 5 AI agents work together to generate content.*

---

## ğŸ¯ The Problem We're Solving

Traditional content generation is a mess. You've probably seen it:

- **Monolithic scripts** that mix data processing, business logic, and output formatting into one giant file
- **Spaghetti dependencies** where changing one thing breaks everything else
- **Zero reusability** â€” need a new content type? Write everything from scratch

We wanted something better. Something that feels more like a **team of specialists** than a one-size-fits-all script.

---

## ğŸ’¡ Our Solution: A Team of Autonomous Agents

Imagine you're running a content agency. You wouldn't have one person do everything. You'd have:

1. **A data person** who cleans and validates incoming data
2. **A researcher** who comes up with the right questions to ask
3. **A product writer** who crafts compelling descriptions
4. **A comparison analyst** who benchmarks against competitors
5. **An FAQ specialist** who answers customer questions

That's exactly what we built â€” but with AI agents.

### How They Work Together

Each agent is **autonomous**:
- It knows what it needs before it can start (its *dependencies*)
- It decides on its own when those dependencies are satisfied
- It does its job and publishes results for others to use

The **orchestrator** simply keeps track of who's done and kicks off whoever's ready next. It doesn't micromanage â€” just coordinates.

---

## ğŸ—ï¸ Architecture Overview

Here's the big picture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ORCHESTRATOR                            â”‚
â”‚  "I keep track of who's done and start whoever's ready"     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              ğŸ“¦ SHARED DATA STATE                   â”‚   â”‚
â”‚   â”‚   "This is where agents drop off their work for     â”‚   â”‚
â”‚   â”‚    other agents to pick up"                         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚          â–¼                 â–¼                 â–¼              â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚     â”‚ ğŸ¤– 5    â”‚      â”‚ ğŸ§  LLM   â”‚      â”‚ ğŸ“ 3     â”‚        â”‚
â”‚     â”‚ Agents  â”‚      â”‚ Client   â”‚      â”‚Templates â”‚        â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ‘¥ Meet the Agents

### 1. ğŸ” Data Parser Agent

**The Gatekeeper**

| | |
|---|---|
| **Job** | Take raw product data and turn it into a clean, validated model |
| **Waits for** | Nothing â€” it goes first |
| **Uses LLM?** | No â€” pure validation |
| **Output** | A Pydantic `Product` model that everyone else can trust |

This agent is simple but crucial. Garbage in, garbage out â€” so it makes sure the data is solid before anyone else touches it.

---

### 2. â“ Question Generation Agent

**The Curious One**

| | |
|---|---|
| **Job** | Generate 15 diverse questions a real user might ask |
| **Waits for** | Parser |
| **Uses LLM?** | Yes â€” crafts natural, varied questions |
| **Output** | Questions across 5 categories: Informational, Safety, Usage, Purchase, Comparison |

Why not hardcode questions? Because real users ask things in unexpected ways. The LLM generates questions that feel human.

---

### 3. ğŸ“¦ Product Page Agent

**The Copywriter**

| | |
|---|---|
| **Job** | Create compelling product page content |
| **Waits for** | Parser |
| **Uses LLM?** | Yes â€” writes marketing copy |
| **Output** | Description, benefits, usage instructions, ingredient explanations, safety info |

This is your product storyteller. It takes dry data and turns it into content that sells.

---

### 4. âš–ï¸ Comparison Agent

**The Analyst**

| | |
|---|---|
| **Job** | Generate a competitor product and analyze differences |
| **Waits for** | Parser |
| **Uses LLM?** | Yes (twice!) â€” first to create a competitor, then to compare |
| **Output** | Two products side-by-side with ingredient, price, and effectiveness comparisons |

The clever part: it *invents* a realistic competitor. No external data needed â€” just smart LLM prompting.

---

### 5. ğŸ’¬ FAQ Generation Agent

**The Helper**

| | |
|---|---|
| **Job** | Answer all the questions from the Question Agent |
| **Waits for** | Parser AND Questions |
| **Uses LLM?** | Yes â€” generates helpful, accurate answers |
| **Output** | 15 Q&A pairs ready for a FAQ page |

This agent has the most dependencies because it needs both the product data AND the questions before it can work.

---

## ğŸ”„ The Execution Flow

Let's walk through what happens when you run `python main.py`:

```
1ï¸âƒ£  INITIALIZE
    â””â”€â”€ Create all 5 agent instances
    â””â”€â”€ Set up the shared data dictionary
    â””â”€â”€ Configure rate limiting (5 sec between LLM agents)

2ï¸âƒ£  LOAD DATA
    â””â”€â”€ Product data goes into shared_data["raw_input"]

3ï¸âƒ£  RUN THE DAG
    â””â”€â”€ Loop until everyone's done:
        â”œâ”€â”€ "Who can run?" (check dependencies)
        â”œâ”€â”€ Run those agents
        â”œâ”€â”€ Store their outputs
        â”œâ”€â”€ Wait for rate limits if needed
        â””â”€â”€ Repeat

4ï¸âƒ£  COLLECT RESULTS
    â””â”€â”€ Grab FAQ, Product, and Comparison outputs

5ï¸âƒ£  SAVE FILES
    â””â”€â”€ Write everything to output/ as JSON
```

---

## ğŸ”€ The DAG (Who Waits for Whom)

This is the dependency graph:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        START â”€â”€â”€â”€â–¶ â”‚ Parser  â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
         â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Questionsâ”‚    â”‚ Product â”‚    â”‚ Comparison â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â”‚               â”‚
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â–¼                      â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”              COMPLETE
     â”‚  FAQ  â”‚                  â–²
     â””â”€â”€â”€â”¬â”€â”€â”€â”˜                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Translation:**
1. Parser runs first (no dependencies)
2. Questions, Product, and Comparison can run next (all just need Parser)
3. FAQ runs last (needs both Parser AND Questions)

---

## ğŸ§  The LLM Integration

We use **Groq** because it's *fast*. Like, really fast.

| Setting | Value |
|---------|-------|
| **Provider** | Groq Cloud |
| **Model** | `llama-3.3-70b-versatile` |
| **Output format** | Structured JSON |
| **Rate limit handling** | Exponential backoff (10s â†’ 20s â†’ 30s) |
| **Max retries** | 3 |
| **Delay between agents** | 5 seconds |

The `llm_client.py` handles all the messy stuff:
- Cleaning up markdown from responses
- Extracting JSON from freeform text
- Retrying on rate limits
- Validating responses

---

## ğŸ“ The Template System

Templates aren't just formatting â€” they're **validation**. Each template checks that the agent output is complete before structuring it.

| Template | Validates | Output Shape |
|----------|-----------|--------------|
| **FAQTemplate** | Every Q&A has both question AND answer | `{page_type, faqs: [{question, answer}]}` |
| **ProductTemplate** | Has name, benefits, usage, ingredients, price | `{page_type, sections: {...}}` |
| **ComparisonTemplate** | Has both products and metrics | `{page_type, products: [], comparison_metrics: []}` |

If something's missing, the template throws an error. No silent failures.

---

## ğŸ› ï¸ Utility Functions

The `content_blocks/generators.py` has pure utility functions for deterministic operations:

| Function | What It Does |
|----------|--------------|
| `extract_product_summary` | Quick one-liner summary of a product |
| `calculate_price_difference` | Math for price comparisons |
| `extract_common_ingredients` | Find what two products share |
| `extract_unique_ingredients` | Find what's unique to one product |

These don't use the LLM â€” they're just reliable helper functions.

---

## ğŸ“‚ Output Files

After a successful run, you'll find these in `output/`:

| File | What's Inside |
|------|---------------|
| `faq.json` | 15 Q&As across 5 categories |
| `product_page.json` | Complete product page sections |
| `comparison_page.json` | Two products + detailed comparison metrics |

All files are **machine-readable JSON** â€” plug them into your CMS, API, or frontend.

---

## ğŸš€ Running the System

### Prerequisites
- Python 3.8 or higher
- A Groq API key (free tier works!)

### Steps

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Set up your API key
echo "GROQ_API_KEY=your_key_here" > .env

# 3. Run it
python main.py
```

### What You'll See

```
============================================================
Kasparro AI - Agentic Content Generation System
============================================================
Starting multi-agent content generation pipeline...

Product: GlowBoost Vitamin C Serum
Price: â‚¹699

Agent execution order based on DAG dependencies...
  parser (no deps) â†’ runs first
  questions, product, comparison (dep: parser) â†’ run after parser
  faq (deps: parser, questions) â†’ runs after questions

----------------------------------------
Executing agents...
----------------------------------------
Using model: llama-3.3-70b-versatile
Executing agent: parser...
Agent parser completed.
Executing agent: questions...
Agent questions completed.
Waiting 5s to respect rate limits...
Executing agent: product...
Agent product completed.
...

âœ“ faq.json
âœ“ product_page.json
âœ“ comparison_page.json

============================================================
All pages generated successfully!
Outputs saved to: output/
============================================================
```

---

## ğŸ”‘ Key Design Principles

### 1. Autonomy
Each agent makes its own decisions. The orchestrator doesn't tell agents *how* to do their job â€” just *when* they can start.

### 2. Modularity
Every piece is a separate module:
- Swap the LLM? Just edit `llm_client.py`
- Add a new agent? Create a file in `agents/` and register it
- Change output format? Modify the template

### 3. Separation of Concerns
- **Agents** = business logic
- **Templates** = output structure
- **LLM Client** = external API
- **Orchestrator** = workflow coordination
- **Models** = data validation

### 4. Fail Gracefully
Rate limits? Retry with backoff. Invalid JSON? Parse what we can. Missing field? Use sensible defaults.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| Language | Python 3.8+ |
| LLM | Groq Cloud (Llama 3.3 70B) |
| Validation | Pydantic |
| Config | python-dotenv |
| Output | JSON |

---

## ğŸ‰ That's It!

You now understand how 5 specialized agents collaborate to turn simple product data into rich, structured content.

The key insight: **let each agent be an expert at one thing**, and **let the orchestrator handle coordination**. It's simpler, more maintainable, and more powerful than a monolithic script.

Happy generating! ğŸš€
